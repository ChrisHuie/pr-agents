# PR Agents

A modular Python library for analyzing GitHub Pull Requests with strict component isolation and type safety.

## ğŸ¯ Project Philosophy

**Separation of Concerns**: Each component operates in complete isolation, preventing context bleeding between different aspects of PR analysis (metadata, code changes, repository info, reviews).

**Type Safety First**: Uses Pydantic models for external API boundaries and dataclasses for internal processing results, ensuring robust type safety throughout the analysis pipeline.

**Testability**: Every component can be tested independently, making the codebase maintainable and reliable.

## ğŸ—ï¸ Architecture Overview

```
External API (GitHub) â†’ Pydantic Models â†’ Extractors â†’ Dataclass Results â†’ Processors â†’ Analysis
```

### Design Principles

1. **Strict Isolation**: Extractors only see their specific component data
2. **No Context Bleeding**: PR title/description never influences code analysis
3. **Dependency Injection**: Components are injected rather than hard-coded
4. **Interface-Based**: Easy to mock and extend
5. **Immutable Processing**: Results are immutable dataclass instances

## ğŸ“ Project Structure

```
pr-agents/
â”œâ”€â”€ src/pr_agents/pr_processing/           # Core processing module
â”‚   â”œâ”€â”€ __init__.py                        # Public API exports
â”‚   â”œâ”€â”€ models.py                          # Pydantic models (external boundaries)
â”‚   â”œâ”€â”€ analysis_models.py                 # Dataclass models (internal results)
â”‚   â”œâ”€â”€ coordinator.py                     # Orchestrates processing pipeline
â”‚   â”‚
â”‚   â”œâ”€â”€ extractors/                        # Component extraction (GitHub API â†’ Python)
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ base.py                        # Base extractor interface
â”‚   â”‚   â”œâ”€â”€ metadata.py                    # PR title, description, labels
â”‚   â”‚   â”œâ”€â”€ code_changes.py                # Diffs, file modifications
â”‚   â”‚   â”œâ”€â”€ repository.py                  # Repo info, branches, languages
â”‚   â”‚   â””â”€â”€ reviews.py                     # Comments, reviews, approvals
â”‚   â”‚
â”‚   â””â”€â”€ processors/                        # Analysis logic (Python â†’ Insights)
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ base.py                        # Base processor interface
â”‚       â”œâ”€â”€ metadata_processor.py          # Quality scoring, pattern detection
â”‚       â”œâ”€â”€ code_processor.py              # Risk assessment, pattern analysis
â”‚       â””â”€â”€ repo_processor.py              # Health scoring, language analysis
â”‚
â”œâ”€â”€ tests/pr_processing/                   # Comprehensive test suite
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ test_processors.py                 # Isolated component tests
â”‚
â”œâ”€â”€ examples/                              # Usage examples
â”‚   â””â”€â”€ pr_analysis_example.py             # Complete workflow demonstration
â”‚
â”œâ”€â”€ .env                                   # Environment variables (not committed)
â”œâ”€â”€ .gitignore                             # Includes .env protection
â”œâ”€â”€ CLAUDE.md                              # Development workflow & standards
â”œâ”€â”€ pyproject.toml                         # Dependencies & tool configuration
â””â”€â”€ README.md                              # This file
```

## ğŸ”§ Component Breakdown

### **Models Layer**

#### **Pydantic Models (`models.py`)**
- **Purpose**: Handle external API data with validation and serialization
- **Used for**: GitHub API responses, data persistence, API boundaries
- **Examples**: `PRMetadata`, `CodeChanges`, `RepositoryInfo`, `ReviewData`

#### **Dataclass Models (`analysis_models.py`)**
- **Purpose**: Internal processing results with better performance
- **Used for**: Analysis outputs, processor results, structured data
- **Examples**: `TitleAnalysis`, `RiskAssessment`, `RepoHealth`

### **Extractors Layer**

**Responsibility**: Convert GitHub API data into structured Python objects

- **`MetadataExtractor`**: Extracts PR title, description, labels, author info
- **`CodeChangesExtractor`**: Extracts file diffs, additions/deletions, patches  
- **`RepositoryExtractor`**: Extracts repo info, languages, branches, topics
- **`ReviewsExtractor`**: Extracts reviews, comments, approval status

**Key Feature**: Each extractor operates in complete isolation - no cross-contamination.

### **Processors Layer**

**Responsibility**: Analyze extracted data and generate insights

- **`MetadataProcessor`**: Quality scoring, title analysis, label categorization
- **`CodeProcessor`**: Risk assessment, pattern detection, file analysis
- **`RepoProcessor`**: Health scoring, language analysis, branch patterns

**Key Feature**: Processors receive only their specific component data, ensuring unbiased analysis.

### **Coordinator Layer**

**Responsibility**: Orchestrate the entire pipeline with controlled data flow

```python
coordinator = PRCoordinator(github_token)

# Extract only specific components
pr_data = coordinator.extract_pr_components(pr_url, {"metadata", "code_changes"})

# Process in isolation  
results = coordinator.process_components(pr_data, ["metadata"])

# Complete analysis
analysis = coordinator.analyze_pr(pr_url)
```

## ğŸš€ Quick Start

### Installation

```bash
git clone <repository-url>
cd pr-agents
uv install  # or pip install -e .
```

### Environment Setup

```bash
# Create .env file
echo "GITHUB_TOKEN=your_github_token_here" > .env
```

### Basic Usage

```python
from pr_agents.pr_processing import PRCoordinator

# Initialize with GitHub token
coordinator = PRCoordinator(github_token)

# Analyze a PR with component isolation
analysis = coordinator.analyze_pr("https://github.com/owner/repo/pull/123")

# Access structured results
metadata_quality = analysis["processing_results"][0]["data"]["metadata_quality"]
print(f"PR Quality: {metadata_quality['quality_level']}")
```

### Selective Processing

```python
# Extract only metadata (no code context bleeding)
pr_data = coordinator.extract_pr_components(
    pr_url, 
    components={"metadata"}
)

# Process only code changes (no metadata influence)
results = coordinator.process_components(
    pr_data, 
    processors=["code_changes"]
)
```

## ğŸ§ª Development Workflow

### Quality Standards

This project follows strict quality standards defined in `CLAUDE.md`:

```bash
# Code formatting
uv run black .

# Linting  
uv run ruff check .

# Testing
uv run pytest

# Complete quality check
uv run black . && uv run ruff check . && uv run pytest
```

### Adding New Components

1. **Create Extractor**: Implement `BaseExtractor` interface
2. **Create Processor**: Implement `BaseProcessor` interface  
3. **Add Models**: Create Pydantic model for external data, dataclass for results
4. **Write Tests**: Ensure complete isolation testing
5. **Update Coordinator**: Register new components

### Testing Philosophy

- **Unit Tests**: Each processor tested in complete isolation
- **Integration Tests**: End-to-end workflow testing
- **Mock Data**: No external API calls in tests
- **Component Isolation**: Verify no context bleeding between components

## ğŸ“Š Analysis Capabilities

### Metadata Analysis
- Title quality scoring and pattern detection
- Description structure analysis  
- Label categorization and completeness
- Overall metadata quality assessment

### Code Analysis
- Risk assessment based on change size and patterns
- File type and modification analysis
- Test coverage detection
- Breaking change pattern recognition
- Security-sensitive file detection

### Repository Analysis  
- Language composition and diversity
- Branch naming convention analysis
- Repository health scoring
- Fork and contribution pattern analysis

## ğŸ”’ Security & Privacy

- **Token Protection**: `.env` files are gitignored to prevent token leakage
- **API Rate Limiting**: Respectful GitHub API usage
- **No Data Storage**: Analysis results are not persisted by default
- **Minimal Permissions**: Requires only read access to public repositories

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Make changes following the quality standards
4. Run quality checks: `uv run black . && uv run ruff check . && uv run pytest`
5. Commit changes (`git commit -m 'Add amazing feature'`)
6. Push to branch (`git push origin feature/amazing-feature`)
7. Open a Pull Request

### Code Style

- **Python 3.13+** required
- **Type hints** for all functions  
- **Docstrings** for all public methods
- **88 character** line length
- **Double quotes** for strings

## ğŸ“œ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- Built with modern Python tooling: `uv`, `black`, `ruff`, `pytest`
- Designed for GitHub API integration with `PyGithub`
- Type safety provided by `Pydantic` and Python dataclasses
- Follows software engineering best practices for maintainability and testability